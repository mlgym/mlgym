{"version":3,"file":"static/js/14.597cc2bb.chunk.js","mappings":"qDAGO,MAAMA,EAAcC,OAAOC,OAAO,CACrCC,WAAY,aACZC,cAAe,gBACfC,kBAAmB,oBACnBC,kBAAmB,oBACnBC,kBAAmB,oBACnBC,cAAe,8DCAnB,MAAMC,EAAyD,CAAC,EAI1DC,EAAuF,CACzF,CAACV,EAAYG,YAAa,CAACQ,EAAYC,KACnCC,ECCO,SAA6BC,GAExC,MAAM,eAAEC,EAAgBC,OAAQC,KAAeC,GAASJ,EACxD,MAAO,CAAEG,gBAAeC,EAC5B,CDLwBC,CAAoBR,GAAOC,EAAQZ,EAAYG,WAAW,EAE9E,CAACH,EAAYI,eAAgB,CAACO,EAAYC,IAAgCQ,QAAQC,IAAI,uBACtF,CAACrB,EAAYK,mBAAoB,CAACM,EAAYC,KAC1C,MAAM,cAAEU,EAAa,eAAEC,EAAc,aAAEC,GE8BhC,SAAoCb,GAE/C,MAAM,cAAEW,EAAa,MAAEG,EAAK,cAAEC,EAAa,YAAEC,GAAgBhB,EAEvDY,EAAgC,GAEhCC,EAA8D,CAAC,EAGrE,IAAK,MAAMI,KAAYF,EACnBF,EAAaI,EAASC,MAAQ,IAAMD,EAASE,QAAUF,EAASG,MAChER,EAAeS,KAAK,CAChBC,SAAUL,EAASC,MAAQ,IAAMD,EAASE,OAC1CI,OAAQZ,EACRG,MAAOA,EACPM,MAAOH,EAASG,QAGxB,IAAK,MAAMH,KAAYD,EACnBH,EAAaI,EAASC,MAAQ,IAAMD,EAASO,MAAQP,EAASG,MAC9DR,EAAeS,KAAK,CAChBC,SAAUL,EAASC,MAAQ,IAAMD,EAASO,KAC1CD,OAAQZ,EACRG,MAAOA,EACPM,MAAOH,EAASG,QAIxB,MAAO,CAAET,gBAAeC,iBAAgBC,eAC5C,CF3DgEY,CAA2BzB,GACnFC,EAAOyB,cAAcL,QAAQT,GAC7BV,EAAgB,CAAES,mBAAkBE,GAAgBZ,EAAO,EAE/D,CAACZ,EAAYM,mBAAoB,CAACK,EAAYC,IAAgCQ,QAAQC,IAAI,oBAC1F,CAACrB,EAAYO,mBAAoB,CAACI,EAAYC,KAC1CC,EGVO,SAAoCyB,GAE/C,MAAM,eAAEvB,EAAc,OAAEC,EAAM,OAAEuB,KAAWrB,GAASoB,EACpD,MAAO,CAEHE,aAAcxB,EAEduB,OAAQA,EAAOE,OAEfC,eAAgBxB,EAAKyB,cAAgBzB,EAAK0B,WAC1CC,eAAgB3B,EAAK4B,cAAgB5B,EAAK6B,eACvC7B,EAEX,CHHwB8B,CAA2BrC,GAAOC,EAAQZ,EAAYO,kBAAkB,GAMhG,SAASM,EAAgBF,EAAWC,GAAgD,IAAD,QAAxBqC,EAAW,uDAAG,GAErEhD,OAAOiD,OAAiC,QAA3B,EAACtC,EAAO,EAAAD,EAAKW,sBAAc,QAA1BV,EAAO,GAAwBD,EAAMA,GAE/CsC,GAAOxC,EAAyBwC,KAEpCxC,EAAyBwC,IAAO,EAEhChD,OAAOkD,KAAKvC,EAAOD,EAAKW,gBAAgB8B,QAAQxC,EAAOyC,QAAQC,IAAK1C,EAAOyC,SAC/E,CAGA,SAASE,EAAcC,EAAiCC,GAEpD,IAAK,MAAM9C,KAAQ6C,EAAoB,CAEnC,MAAME,EAAmB/C,EACzB,GAAkC,mBAA9B+C,EAAiBC,SAA+B,CAEhDJ,EAAcG,EAAiB/C,KAAM8C,GACrC,QAIJ,CAEA,MAAQ9C,MAAM,WAAEiD,EAAU,QAAEC,IAAclD,EAE1CD,EAAkBkD,GAA8CC,EAASJ,EAC7E,CACJ,CAeO,MAAMK,EAA4BN,IAErC,MAAMC,EAA+B,CACjCJ,QAAS,IAAIU,IACb1B,cAAe,IAGnBkB,EAAcC,EAAoBC,GAElCO,YArBJ,SAAqC,GAAyE,IAAzE,QAAEX,EAAO,cAAEhB,KAAkB4B,GAA4B,EAI1F,MAAO,CACHC,aAAcb,EAAQc,KAAO,EAAI,IAAId,QAAWe,EAChDC,UAAWpE,OAAOqE,OAAOL,GACzB5B,cAAeA,EAEvB,CAYgBkC,CAA4Bd,GAAe,EAI9Ce,EAA0BC,IACnCT,YAAY,CAAEhD,OAAQ,CAAEyD,SAAwB,EAGvCC,EAA+B,CAACC,EAA4BC,EAAuBC,KAC5Fb,YAAY,CAAEhD,OAAQ,CAAE2D,oBAAmBC,eAAcC,eAA8B,EAO9EC,EAAgCC,IACzCf,YAAY,CAAEhD,OAAQ,CAAE+D,eAA8B,EIjG1D,IAAIC,EAEAC,EAEJ,IAAIC,GAAoB,EACpBC,GAAoB,EAEpBC,EAA4B,EAEhC,MAEMC,EAA2B,GACjC,IAAIC,EAGJ,MAYMC,EAAY,CAACP,EAAgBJ,EAAsBC,KAGrDG,EAAOQ,KAAK,OAAQ,CAAEC,MAAO,CAACb,KAE9BK,EAAmBS,YAAYC,EAA+BC,IAAeZ,GAE7EN,GAA6B,EAAME,EAAcC,GAEjDS,EAAqBI,aAAY,KAAQL,EAAYQ,OAAS,GAAKC,GAAsB,GAAIC,IAAsC,EAGjIC,EAAgBC,GAAoCC,EAAKD,GAEzDE,EAAWC,GAAeF,EAAKE,GAG/BC,EAAuBC,IAGzBjB,EAAYrD,KAAKsE,GAEbjB,EAAYQ,QAvCoB,KAwChCC,IAGJV,IJwCApB,YAAY,CAAEhD,OAAQ,uBItCW,EAI/BuF,EAAoC,KAEtCpB,GAAW,IAAIqB,MAAOC,UAEtBjC,EAAuBW,EAAWD,EAAS,EAMzCS,EAAiCX,KAG/BG,EAAWD,IAA0B,IAAdA,KAEvBA,GAAW,IAAIsB,MAAOC,UAEtBzB,EAAOQ,KAAK,SAGhBV,EAA6BM,EA5EV,GA8EnBA,EAAoB,CAAC,EAGnBc,EAAQQ,IACVtF,QAAQC,IAAI,GAAD,OAAIqF,aAAeC,MAAQ,aAA2B,eAAc,cAAMD,IAErFE,cAAc3B,GAEd2B,cAActB,GAEdD,EAAYQ,OAAS,GAAKC,IAE1BpB,GAA6B,GAE7BI,EAA6B,GAE7BN,EAAuB,EAAE,EAIvBsB,EAAuB,KAEzBhC,EAAyBuB,GAEzBA,EAAYQ,OAAS,CAAC,EAK1BgB,UAAY,IAA6B,IAA5B,KAAElG,GAAoB,EA/FfmG,MAiGH,iBAATnG,EACAqE,EAAO+B,aAEoB3C,IAAtBzD,EAAKiE,mBAA2DR,IAA7BzD,EAAKqG,qBApGjCF,EAsGDnG,EArGfS,QAAQC,IAAI,6BACZ2D,GAASiC,EAAAA,EAAAA,IAASH,EAAeE,oBAAqB,CAAEE,aAAa,IACrElC,EAAOmC,GAAG,WAAW,IAAM5B,EAAUP,EAAQ8B,EAAelC,aAAckC,EAAejC,cACzFG,EAAOmC,GAAG,aAAcnB,GACxBhB,EAAOmC,GAAG,gBAAiBhB,GAC3BnB,EAAOmC,GAAG,cAAed,GACzBrB,EAAOmC,GAAG,OAAQZ,IAkGdnF,QAAQC,IAAIV,EAAK,C,GC5HrByG,EAA2B,CAAC,EAGhC,SAASC,EAAoBC,GAE5B,IAAIC,EAAeH,EAAyBE,GAC5C,QAAqBlD,IAAjBmD,EACH,OAAOA,EAAaC,QAGrB,IAAIC,EAASL,EAAyBE,GAAY,CAGjDE,QAAS,CAAC,GAOX,OAHAE,EAAoBJ,GAAUG,EAAQA,EAAOD,QAASH,GAG/CI,EAAOD,OACf,CAGAH,EAAoBM,EAAID,EAGxBL,EAAoBO,EAAI,KAGvB,IAAIC,EAAsBR,EAAoBS,OAAE1D,EAAW,CAAC,MAAM,IAAOiD,EAAoB,MAE7F,OADAQ,EAAsBR,EAAoBS,EAAED,EAClB,E,MCjC3B,IAAIE,EAAW,GACfV,EAAoBS,EAAI,CAACE,EAAQC,EAAUC,EAAIC,KAC9C,IAAGF,EAAH,CAMA,IAAIG,EAAeC,IACnB,IAASC,EAAI,EAAGA,EAAIP,EAASlC,OAAQyC,IAAK,CACrCL,EAAWF,EAASO,GAAG,GACvBJ,EAAKH,EAASO,GAAG,GACjBH,EAAWJ,EAASO,GAAG,GAE3B,IAJA,IAGIC,GAAY,EACPC,EAAI,EAAGA,EAAIP,EAASpC,OAAQ2C,MACpB,EAAXL,GAAsBC,GAAgBD,IAAalI,OAAOkD,KAAKkE,EAAoBS,GAAGW,OAAOxF,GAASoE,EAAoBS,EAAE7E,GAAKgF,EAASO,MAC9IP,EAASS,OAAOF,IAAK,IAErBD,GAAY,EACTJ,EAAWC,IAAcA,EAAeD,IAG7C,GAAGI,EAAW,CACbR,EAASW,OAAOJ,IAAK,GACrB,IAAIK,EAAIT,SACE9D,IAANuE,IAAiBX,EAASW,EAC/B,CACD,CACA,OAAOX,CArBP,CAJCG,EAAWA,GAAY,EACvB,IAAI,IAAIG,EAAIP,EAASlC,OAAQyC,EAAI,GAAKP,EAASO,EAAI,GAAG,GAAKH,EAAUG,IAAKP,EAASO,GAAKP,EAASO,EAAI,GACrGP,EAASO,GAAK,CAACL,EAAUC,EAAIC,EAuBjB,C,KC3Bdd,EAAoBuB,EAAI,CAACpB,EAASqB,KACjC,IAAI,IAAI5F,KAAO4F,EACXxB,EAAoByB,EAAED,EAAY5F,KAASoE,EAAoByB,EAAEtB,EAASvE,IAC5EhD,OAAO8I,eAAevB,EAASvE,EAAK,CAAE+F,YAAY,EAAMC,IAAKJ,EAAW5F,IAE1E,ECNDoE,EAAoB6B,EAAI,CAAC,EAGzB7B,EAAoB8B,EAAKC,GACjBC,QAAQC,IAAIrJ,OAAOkD,KAAKkE,EAAoB6B,GAAGK,QAAO,CAACC,EAAUvG,KACvEoE,EAAoB6B,EAAEjG,GAAKmG,EAASI,GAC7BA,IACL,KCNJnC,EAAoBoC,EAAKL,GAEjB,aAAeA,EAAf,qBCFR/B,EAAoBqC,SAAYN,IAEf,ECHjB/B,EAAoByB,EAAI,CAACa,EAAKC,IAAU3J,OAAO4J,UAAUC,eAAeC,KAAKJ,EAAKC,GCClFvC,EAAoBsB,EAAKnB,IACH,qBAAXwC,QAA0BA,OAAOC,aAC1ChK,OAAO8I,eAAevB,EAASwC,OAAOC,YAAa,CAAEC,MAAO,WAE7DjK,OAAO8I,eAAevB,EAAS,aAAc,CAAE0C,OAAO,GAAO,ECL9D7C,EAAoB8C,EAAI,U,MCIxB,IAAIC,EAAkB,CACrB,GAAI,GAkBL/C,EAAoB6B,EAAEZ,EAAI,CAACc,EAASI,KAE/BY,EAAgBhB,IAElBiB,cAAchD,EAAoB8C,EAAI9C,EAAoBoC,EAAEL,GAE9D,EAGD,IAAIkB,EAAqBC,KAA4B,sBAAIA,KAA4B,uBAAK,GACtFC,EAA6BF,EAAmBtI,KAAKyI,KAAKH,GAC9DA,EAAmBtI,KAzBCrB,IACnB,IAAIsH,EAAWtH,EAAK,GAChB+J,EAAc/J,EAAK,GACnBgK,EAAUhK,EAAK,GACnB,IAAI,IAAI2G,KAAYoD,EAChBrD,EAAoByB,EAAE4B,EAAapD,KACrCD,EAAoBM,EAAEL,GAAYoD,EAAYpD,IAIhD,IADGqD,GAASA,EAAQtD,GACdY,EAASpC,QACduE,EAAgBnC,EAAS2C,OAAS,EACnCJ,EAA2B7J,EAAK,C,WCrBjC,IAAIkK,EAAOxD,EAAoBO,EAC/BP,EAAoBO,EAAI,IAChBP,EAAoB8B,EAAE,KAAK2B,KAAKD,E,KCDdxD,EAAoBO,G","sources":["worker_socket/EventsTypes.ts","worker_socket/MainThreadCallbacks.ts","worker_socket/event_handlers/JobStatusHandler.ts","worker_socket/event_handlers/EvaluationResultHandler.ts","worker_socket/event_handlers/ExperimentStatusHandler.ts","worker_socket/WorkerSocket.ts","../webpack/bootstrap","../webpack/runtime/chunk loaded","../webpack/runtime/define property getters","../webpack/runtime/ensure chunk","../webpack/runtime/get javascript chunk filename","../webpack/runtime/get mini-css chunk filename","../webpack/runtime/hasOwnProperty shorthand","../webpack/runtime/make namespace object","../webpack/runtime/publicPath","../webpack/runtime/importScripts chunk loading","../webpack/runtime/startup chunk dependencies","../webpack/startup"],"sourcesContent":["// as no more event types are going to be created, it's better to have all of them just here in one place instead of defined in their own files with their handlers\n\n// the name of 'mlgym_event's received on the socket\nexport const MLGYM_EVENT = Object.freeze({\n    JOB_STATUS: \"job_status\",\n    JOB_SCHEDULED: \"job_scheduled\",\n    EVALUATION_RESULT: \"evaluation_result\",\n    EXPERIMENT_CONFIG: \"experiment_config\",\n    EXPERIMENT_STATUS: \"experiment_status\",\n    UNKNOWN_EVENT: \"Unknown event type. No event handler for such event type.\",\n});","import { Row } from \"../redux/table/tableSlice\";\nimport { BufferedDataFromSocket, DataFromSocket, DataToRedux, UpdatesObject } from \"./DataTypes\";\nimport { MLGYM_EVENT } from \"./EventsTypes\";\nimport handleEvaluationResultData from \"./event_handlers/EvaluationResultHandler\";\nimport handleExperimentStatusData from \"./event_handlers/ExperimentStatusHandler\";\nimport handleJobStatusData from \"./event_handlers/JobStatusHandler\";\n\n// ========================= variables ============================//\n\nconst MapEventsFirstOccurrence: { [event: string]: boolean } = {};\n// const TableHeaders: Set<string> = new Set();\n\n// Hashing is faster instead of switching over the the eventType\nconst MapEventToProcess: { [event: string]: (input: JSON, output: UpdatesObject) => void } = {\n    [MLGYM_EVENT.JOB_STATUS]: (data: JSON, update: UpdatesObject): void => {\n        processForTable(handleJobStatusData(data), update, MLGYM_EVENT.JOB_STATUS);\n    },\n    [MLGYM_EVENT.JOB_SCHEDULED]: (data: JSON, update: UpdatesObject): void => console.log(\"Job scheduled found\"),\n    [MLGYM_EVENT.EVALUATION_RESULT]: (data: JSON, update: UpdatesObject): void => {\n        const { experiment_id, charts_updates, table_scores } = handleEvaluationResultData(data);\n        update.chartsUpdates.push(...charts_updates); // process for Charts\n        processForTable({ experiment_id, ...table_scores }, update); // process for Table\n    },\n    [MLGYM_EVENT.EXPERIMENT_CONFIG]: (data: JSON, update: UpdatesObject): void => console.log(\"Exp config found\"),\n    [MLGYM_EVENT.EXPERIMENT_STATUS]: (data: JSON, update: UpdatesObject): void => {\n        processForTable(handleExperimentStatusData(data), update, MLGYM_EVENT.EXPERIMENT_STATUS);\n    },\n};\n\n// ========================= helper methods ============================//\n// prepares the rows and the headers of the table\nfunction processForTable(data: Row, update: UpdatesObject, key: string = \"\"): void {\n    // if defined then merge otherwise take the data as the initial value\n    Object.assign(update[data.experiment_id] ??= data, data);\n    // check if the event_type is provided and if it was the first occurrence? if so return\n    if (key && MapEventsFirstOccurrence[key]) return;\n    // set the flag in order to not form the headers again\n    MapEventsFirstOccurrence[key] = true;\n    // else add every key in the row object to the headers\n    Object.keys(update[data.experiment_id]).forEach(update.headers.add, update.headers);\n}\n\n// loops over buffers, whether created by the websocket or received as a buffered message\nfunction processBuffer(bufferedSocketData: Array<JSON>, updatesHolder: UpdatesObject): void {\n    // loop over all incoming data from socket\n    for (const data of bufferedSocketData) {\n        // assume incoming data type to be BufferedDataFromSocket and verify the event_id\n        const data_from_socket = data as BufferedDataFromSocket;\n        if (data_from_socket.event_id === \"batched_events\") {\n            // if that's the case then do a recursive call on the data and skip afterwards\n            processBuffer(data_from_socket.data, updatesHolder)\n            continue;\n            // NOTE: due to the nature of the incoming messages we know that there is \n            // never a BufferedDataFromSocket inside of another BufferedDataFromSocket\n            // so it's safe to say that this recursion is 1-level-deep only!\n        }\n        // parse data from socket then extract event_type and payload\n        const { data: { event_type, payload } } = data as DataFromSocket;\n        // process the payload and load it into the UpdatesObject Object to be later processed into DataToRedux object\n        MapEventToProcess[event_type as keyof typeof MapEventToProcess](payload, updatesHolder);\n    }\n}\n\n// prepare the update to match the redux accepted format \nfunction processUpdatesIntoReduxData({ headers, chartsUpdates, ...experiments }: UpdatesObject): DataToRedux {\n    // TODO: maybe compare the size of the set to its previous size instead of sending every time? \n    // NOTE: currently because of the different headers that are received everytime \n    // because of the MLGYM_EVENT.EVALUATION_RESULT, sending nearly all the time is inevitable \n    return {\n        tableHeaders: headers.size > 0 ? [...headers] : undefined,\n        tableData: Object.values(experiments),\n        chartsUpdates: chartsUpdates,\n    };\n}\n\n// ========================= Callbacks to update the MainThread ============================//\nexport const updateMainThreadCallback = (bufferedSocketData: Array<JSON>) => {\n    // create a place holder for the incoming updates\n    const updatesHolder: UpdatesObject = {\n        headers: new Set(),\n        chartsUpdates: []\n    };\n    // Process the buffer coming from the socket and populate updatesHolder object accordingly\n    processBuffer(bufferedSocketData, updatesHolder);\n    // sending Data to the Main thread to store it in Redux after processing it into the right format\n    postMessage(processUpdatesIntoReduxData(updatesHolder));\n};\n\n// NOTE: no need to buffer these callbacks as we want them to be in real time!!!\nexport const pingMainThreadCallback = (ping: number) => {\n    postMessage({ status: { ping } } as DataToRedux);\n};\n\nexport const connectionMainThreadCallback = (isSocketConnected: boolean, gridSearchId?: string, restApiUrl?: string) => {\n    postMessage({ status: { isSocketConnected, gridSearchId, restApiUrl } } as DataToRedux);\n};\n\nexport const msgCounterIncMainThreadCallback = () => {\n    postMessage({ status: \"msg_count_increment\" } as DataToRedux);\n};\n\nexport const throughputMainThreadCallback = (throughput: number) => {\n    postMessage({ status: { throughput } } as DataToRedux);\n};\n","import { Row } from \"../../redux/table/tableSlice\";\n\ninterface JobStatusPayload extends JSON {\n    \"job_id\": string; // \"2022-11-23--20-08-38-17\",\n    \"job_type\": string; // 1,\n    \"status\": string; // \"RUNNING\",\n    \"grid_search_id\": string; // \"2022-11-23--20-08-38\",\n    \"experiment_id\": number; //  17,\n    \"starting_time\": number; // 1669234123.8701758,\n    \"finishing_time\": number; // -1,\n    \"device\": string; // \"cuda:4\",\n    \"error\": string; // null,\n    \"stacktrace\": string; // null\n}\n\n// transform JSON data into Row (the Job part):\nexport default function handleJobStatusData(jobData: JSON): Row {\n    // remove grid_search_id + key renaming \"status\" to \"job_status\"\n    const { grid_search_id, status: job_status, ...rest } = jobData as JobStatusPayload;\n    return { job_status, ...rest } as Row;\n}","// interface data_evaluation_result {\n//     \"grid_search_id\": \"2022-11-23--20-08-38\",\n//     \"experiment_id\": 18,\n//     \"epoch\": 0,\n//     \"metric_scores\": [{\n//         \"metric\": \"F1_SCORE_macro\",\n//         \"split\": \"train\",\n//         \"score\": 0.04199189495669321\n//     }, {\n//         \"metric\": \"PRECISION_macro\",\n//         \"split\": \"train\",\n//         \"score\": 0.052925666019545944\n//     }, {\n//         \"metric\": \"RECALL_macro\",\n//         \"split\": \"train\",\n//         \"score\": 0.100662497082089\n//     }],\n//     \"loss_scores\": [{\n//         \"loss\": \"cross_entropy_loss\",\n//         \"split\": \"train\",\n//         \"score\": 2.3039234473024095\n//     }]\n// }\n\n// ============================ Input shape ================================\ninterface EvaluationResultPayload extends JSON {\n    epoch: number, // string, // in Graph.tsx parsing: false, \n    grid_search_id: string,\n    experiment_id: number,\n    metric_scores: Array<Score>,\n    loss_scores: Array<Score>\n}\n\ninterface Score {\n    metric?: string,\n    loss?: string,\n    split: string,\n    score: number\n}\n\n// ============================ Output shape ===============================\nexport interface ChartUpdate {\n    chart_id: string,\n    exp_id: number,\n    epoch: number, //string, // in Graph.tsx parsing: false, \n    score: number\n}\n\n// ============================ Main function ==============================\nexport default function handleEvaluationResultData(data: JSON) {\n    // parse the incoming data to EvaluationResultPayload and destruct it\n    const { experiment_id, epoch, metric_scores, loss_scores } = data as EvaluationResultPayload;\n    // to append to experiment values in the charts\n    const charts_updates: ChartUpdate[] = [];\n    // for saving the latest score values to update the table\n    const table_scores: { [latest_split_metric_key: string]: number } = {};\n\n    // loop over the metrics and another over the losses\n    for (const scoreObj of metric_scores) {\n        table_scores[scoreObj.split + \"_\" + scoreObj.metric] = scoreObj.score;\n        charts_updates.push({\n            chart_id: scoreObj.split + \"_\" + scoreObj.metric,\n            exp_id: experiment_id,\n            epoch: epoch,\n            score: scoreObj.score\n        });\n    }\n    for (const scoreObj of loss_scores) {\n        table_scores[scoreObj.split + \"_\" + scoreObj.loss] = scoreObj.score;\n        charts_updates.push({\n            chart_id: scoreObj.split + \"_\" + scoreObj.loss,\n            exp_id: experiment_id,\n            epoch: epoch,\n            score: scoreObj.score\n        });\n    }\n\n    return { experiment_id, charts_updates, table_scores };\n}","import { Row } from \"../../redux/table/tableSlice\";\n\ninterface ExperimentStatusPayload extends JSON {\n    \"grid_search_id\": string;// \"2022-11-23--20-08-38\",\n    \"experiment_id\": number; // 6,\n    \"status\": string; // \"evaluation\",\n    \"num_epochs\": number;// 100,\n    \"current_epoch\": number;// 0,\n    \"splits\": Array<string>; // [\"train\", \"val\", \"test\"],\n    \"current_split\": string;// \"train\",\n    \"num_batches\": number; // 8400,\n    \"current_batch\": number;// 840\n}\n\n// transform JSON data into Row (the Experiment part):\nexport default function handleExperimentStatusData(expData: JSON): Row {\n    // 1. remove grid_search_id\n    const { grid_search_id, status, splits, ...rest } = expData as ExperimentStatusPayload;\n    return {\n        // 2. key renaming \"status\" to \"model_status\"\n        model_status: status,\n        // 3. (extra) progresses calculating & storing them \n        splits: splits.join(),\n        // 4. (extra) turn the split array into string\n        epoch_progress: rest.current_epoch / rest.num_epochs,\n        batch_progress: rest.current_batch / rest.num_batches,\n        ...rest\n    } as Row;\n}","import socketIO, { Socket } from 'socket.io-client';\nimport { settingConfigsInterface } from '../app/App';\nimport { connectionMainThreadCallback, msgCounterIncMainThreadCallback, pingMainThreadCallback, throughputMainThreadCallback, updateMainThreadCallback } from './MainThreadCallbacks';\n\n// ========================= variables ============================//\nlet socket: Socket; // 'let' to initialize on funciton call\n// Ping to measure Round Trip Time (RTT)\nlet pinging_interval: NodeJS.Timer; // for idealy pinging the server\nconst period: number = 1; // specifying how long the pinging_interval in seconds\nlet lastPing: number = -1;\nlet lastPong: number = -1; // the actual ping is calculated = lastPong - lastPing\n// A counter to measure the throughput\nlet msgCountPerPeriod: number = 0;\n// Buffering Window\nconst BUFFER_WINDOW_LIMIT_IN_SECONDS = 1;\nconst BUFFER_WINDOW_LIMIT_IN_MESSAGES = 1000;\nconst bufferQueue: Array<JSON> = []; //NOTE: no fear of a race conditions as JS runs on a single thread!\nlet buffering_interval: NodeJS.Timer;\n\n// =~=~=~=~=~=~=~=~=~=~=~=~=~= ~WebSocket~ =~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=//\nconst initSocket = (settingConfigs: settingConfigsInterface) => {\n    console.log(\"WebSocket initializing...\");\n    socket = socketIO(settingConfigs.socketConnectionUrl, { autoConnect: true });\n    socket.on('connect', () => onConnect(socket, settingConfigs.gridSearchId, settingConfigs.restApiUrl));\n    socket.on('disconnect', onDisconnect);\n    socket.on('connect_error', onError);\n    socket.on('mlgym_event', process_mlgym_event);\n    socket.on('pong', onPongReceivedfromWebsocketServer);\n};\n\n\n// ========================= connection events ============================//\nconst onConnect = (socket: Socket, gridSearchId: string, restApiUrl: string) => {\n    //NOTE: for testing with the dummy_server.py set runId = \"mlgym_event_subscribers\";\n    // Max added bug report here: https://github.com/mlgym/mlgym/issues/134\n    socket.emit('join', { rooms: [gridSearchId] });\n    // start periodic server pining\n    pinging_interval = setInterval(send_ping_to_websocket_server, period * 1000, socket);\n    // flag main thread that connection is on\n    connectionMainThreadCallback(true, gridSearchId, restApiUrl);\n    // start periodic buffer flushing\n    buffering_interval = setInterval(() => { bufferQueue.length > 0 && flushBufferingWindow() }, BUFFER_WINDOW_LIMIT_IN_SECONDS * 1000);\n};\n\nconst onDisconnect = (reason: Socket.DisconnectReason) => stop(reason);\n\nconst onError = (err: Error) => stop(err);\n\n// ========================= data driven events ============================//\nconst process_mlgym_event = (msg: JSON) => {\n    // TODO: maybe here instead of just pushing, insert based on the \"event_id\" or \"creation_ts\"\n    // push in the buffer\n    bufferQueue.push(msg);\n    // flush if bufferQueue is full\n    if (bufferQueue.length >= BUFFER_WINDOW_LIMIT_IN_MESSAGES) {\n        flushBufferingWindow();\n    }\n    // message count for calculating the throughput\n    msgCountPerPeriod++;\n    // flag main thread to increment the number of incoming messages\n    msgCounterIncMainThreadCallback();\n};\n\n// onPong or onPongReceived\nconst onPongReceivedfromWebsocketServer = () => {\n    // on Pong , save time of receiving \n    lastPong = new Date().getTime();\n    // calculate the ping and send it to the MainThread\n    pingMainThreadCallback(lastPong - lastPing);\n};\n\n// ========================= helper methods ============================//\n\n// sendPingToServer or sendPing or pingToServer or pingingServer or pinging\nconst send_ping_to_websocket_server = (socket: Socket) => {\n    // if Pong was received after sending a Ping \n    // if no Ping was sent before\n    if (lastPong > lastPing || lastPing === -1) {\n        // save ping time\n        lastPing = new Date().getTime();\n        // ping the server\n        socket.emit('ping');\n    }\n    // calculate throughput and send it to the main thread\n    throughputMainThreadCallback(msgCountPerPeriod / period);\n    // reset message count to calculate throughput\n    msgCountPerPeriod = 0;\n};\n\nconst stop = (why: Error | Socket.DisconnectReason) => {\n    console.log(`${why instanceof Error ? \"connection\" /* error */ : \"disconnected\"} : ${why}`);\n    // halt periodic server pining\n    clearInterval(pinging_interval);\n    // halt periodic buffering\n    clearInterval(buffering_interval);\n    // flush just in case something is still in the buffer\n    bufferQueue.length > 0 && flushBufferingWindow();\n    // flag main thread that connection is off\n    connectionMainThreadCallback(false);\n    // force throughput back to 0, as it won't update when the interval is cleared\n    throughputMainThreadCallback(0);\n    // force ping back to 0, it doesn't make sense to update it accurately if the connection is down anyways\n    pingMainThreadCallback(0);\n};\n\n// flush regardless whether the bufferQueue is full or not\nconst flushBufferingWindow = () => {\n    // update the redux state on the main thread\n    updateMainThreadCallback(bufferQueue);\n    // clear the buffer\n    bufferQueue.length = 0;\n};\n\n// =~=~=~=~=~=~=~=~=~=~=~=~=~= ~WebWorker~ =~=~=~=~=~=~=~=~=~=~=~=~=~=~=~=//\n// in the beginning and at the end\nonmessage = ({ data }: MessageEvent) => {\n    // for closing the socket!\n    if (data === \"CLOSE_SOCKET\")\n        socket.close();\n    // sending the URL to the socket and other initialization parameters!\n    else if (data.gridSearchId !== undefined && data.socketConnectionUrl !== undefined)\n        // data is settingConfigs\n        initSocket(data);\n    // Debugging purposes \n    else\n        console.log(data);\n};\n","// The module cache\nvar __webpack_module_cache__ = {};\n\n// The require function\nfunction __webpack_require__(moduleId) {\n\t// Check if module is in cache\n\tvar cachedModule = __webpack_module_cache__[moduleId];\n\tif (cachedModule !== undefined) {\n\t\treturn cachedModule.exports;\n\t}\n\t// Create a new module (and put it into the cache)\n\tvar module = __webpack_module_cache__[moduleId] = {\n\t\t// no module.id needed\n\t\t// no module.loaded needed\n\t\texports: {}\n\t};\n\n\t// Execute the module function\n\t__webpack_modules__[moduleId](module, module.exports, __webpack_require__);\n\n\t// Return the exports of the module\n\treturn module.exports;\n}\n\n// expose the modules object (__webpack_modules__)\n__webpack_require__.m = __webpack_modules__;\n\n// the startup function\n__webpack_require__.x = () => {\n\t// Load entry module and return exports\n\t// This entry module depends on other loaded chunks and execution need to be delayed\n\tvar __webpack_exports__ = __webpack_require__.O(undefined, [428], () => (__webpack_require__(14)))\n\t__webpack_exports__ = __webpack_require__.O(__webpack_exports__);\n\treturn __webpack_exports__;\n};\n\n","var deferred = [];\n__webpack_require__.O = (result, chunkIds, fn, priority) => {\n\tif(chunkIds) {\n\t\tpriority = priority || 0;\n\t\tfor(var i = deferred.length; i > 0 && deferred[i - 1][2] > priority; i--) deferred[i] = deferred[i - 1];\n\t\tdeferred[i] = [chunkIds, fn, priority];\n\t\treturn;\n\t}\n\tvar notFulfilled = Infinity;\n\tfor (var i = 0; i < deferred.length; i++) {\n\t\tvar chunkIds = deferred[i][0];\n\t\tvar fn = deferred[i][1];\n\t\tvar priority = deferred[i][2];\n\t\tvar fulfilled = true;\n\t\tfor (var j = 0; j < chunkIds.length; j++) {\n\t\t\tif ((priority & 1 === 0 || notFulfilled >= priority) && Object.keys(__webpack_require__.O).every((key) => (__webpack_require__.O[key](chunkIds[j])))) {\n\t\t\t\tchunkIds.splice(j--, 1);\n\t\t\t} else {\n\t\t\t\tfulfilled = false;\n\t\t\t\tif(priority < notFulfilled) notFulfilled = priority;\n\t\t\t}\n\t\t}\n\t\tif(fulfilled) {\n\t\t\tdeferred.splice(i--, 1)\n\t\t\tvar r = fn();\n\t\t\tif (r !== undefined) result = r;\n\t\t}\n\t}\n\treturn result;\n};","// define getter functions for harmony exports\n__webpack_require__.d = (exports, definition) => {\n\tfor(var key in definition) {\n\t\tif(__webpack_require__.o(definition, key) && !__webpack_require__.o(exports, key)) {\n\t\t\tObject.defineProperty(exports, key, { enumerable: true, get: definition[key] });\n\t\t}\n\t}\n};","__webpack_require__.f = {};\n// This file contains only the entry chunk.\n// The chunk loading function for additional chunks\n__webpack_require__.e = (chunkId) => {\n\treturn Promise.all(Object.keys(__webpack_require__.f).reduce((promises, key) => {\n\t\t__webpack_require__.f[key](chunkId, promises);\n\t\treturn promises;\n\t}, []));\n};","// This function allow to reference async chunks and sibling chunks for the entrypoint\n__webpack_require__.u = (chunkId) => {\n\t// return url for filenames based on template\n\treturn \"static/js/\" + chunkId + \".\" + \"caa75c65\" + \".chunk.js\";\n};","// This function allow to reference async chunks and sibling chunks for the entrypoint\n__webpack_require__.miniCssF = (chunkId) => {\n\t// return url for filenames based on template\n\treturn undefined;\n};","__webpack_require__.o = (obj, prop) => (Object.prototype.hasOwnProperty.call(obj, prop))","// define __esModule on exports\n__webpack_require__.r = (exports) => {\n\tif(typeof Symbol !== 'undefined' && Symbol.toStringTag) {\n\t\tObject.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });\n\t}\n\tObject.defineProperty(exports, '__esModule', { value: true });\n};","__webpack_require__.p = \"/mlgym/\";","// no baseURI\n\n// object to store loaded chunks\n// \"1\" means \"already loaded\"\nvar installedChunks = {\n\t14: 1\n};\n\n// importScripts chunk loading\nvar installChunk = (data) => {\n\tvar chunkIds = data[0];\n\tvar moreModules = data[1];\n\tvar runtime = data[2];\n\tfor(var moduleId in moreModules) {\n\t\tif(__webpack_require__.o(moreModules, moduleId)) {\n\t\t\t__webpack_require__.m[moduleId] = moreModules[moduleId];\n\t\t}\n\t}\n\tif(runtime) runtime(__webpack_require__);\n\twhile(chunkIds.length)\n\t\tinstalledChunks[chunkIds.pop()] = 1;\n\tparentChunkLoadingFunction(data);\n};\n__webpack_require__.f.i = (chunkId, promises) => {\n\t// \"1\" is the signal for \"already loaded\"\n\tif(!installedChunks[chunkId]) {\n\t\tif(true) { // all chunks have JS\n\t\t\timportScripts(__webpack_require__.p + __webpack_require__.u(chunkId));\n\t\t}\n\t}\n};\n\nvar chunkLoadingGlobal = self[\"webpackChunkfront_end\"] = self[\"webpackChunkfront_end\"] || [];\nvar parentChunkLoadingFunction = chunkLoadingGlobal.push.bind(chunkLoadingGlobal);\nchunkLoadingGlobal.push = installChunk;\n\n// no HMR\n\n// no HMR manifest","var next = __webpack_require__.x;\n__webpack_require__.x = () => {\n\treturn __webpack_require__.e(428).then(next);\n};","// run startup\nvar __webpack_exports__ = __webpack_require__.x();\n"],"names":["MLGYM_EVENT","Object","freeze","JOB_STATUS","JOB_SCHEDULED","EVALUATION_RESULT","EXPERIMENT_CONFIG","EXPERIMENT_STATUS","UNKNOWN_EVENT","MapEventsFirstOccurrence","MapEventToProcess","data","update","processForTable","jobData","grid_search_id","status","job_status","rest","handleJobStatusData","console","log","experiment_id","charts_updates","table_scores","epoch","metric_scores","loss_scores","scoreObj","split","metric","score","push","chart_id","exp_id","loss","handleEvaluationResultData","chartsUpdates","expData","splits","model_status","join","epoch_progress","current_epoch","num_epochs","batch_progress","current_batch","num_batches","handleExperimentStatusData","key","assign","keys","forEach","headers","add","processBuffer","bufferedSocketData","updatesHolder","data_from_socket","event_id","event_type","payload","updateMainThreadCallback","Set","postMessage","experiments","tableHeaders","size","undefined","tableData","values","processUpdatesIntoReduxData","pingMainThreadCallback","ping","connectionMainThreadCallback","isSocketConnected","gridSearchId","restApiUrl","throughputMainThreadCallback","throughput","socket","pinging_interval","lastPing","lastPong","msgCountPerPeriod","bufferQueue","buffering_interval","onConnect","emit","rooms","setInterval","send_ping_to_websocket_server","period","length","flushBufferingWindow","BUFFER_WINDOW_LIMIT_IN_SECONDS","onDisconnect","reason","stop","onError","err","process_mlgym_event","msg","onPongReceivedfromWebsocketServer","Date","getTime","why","Error","clearInterval","onmessage","settingConfigs","close","socketConnectionUrl","socketIO","autoConnect","on","__webpack_module_cache__","__webpack_require__","moduleId","cachedModule","exports","module","__webpack_modules__","m","x","__webpack_exports__","O","deferred","result","chunkIds","fn","priority","notFulfilled","Infinity","i","fulfilled","j","every","splice","r","d","definition","o","defineProperty","enumerable","get","f","e","chunkId","Promise","all","reduce","promises","u","miniCssF","obj","prop","prototype","hasOwnProperty","call","Symbol","toStringTag","value","p","installedChunks","importScripts","chunkLoadingGlobal","self","parentChunkLoadingFunction","bind","moreModules","runtime","pop","next","then"],"sourceRoot":""}